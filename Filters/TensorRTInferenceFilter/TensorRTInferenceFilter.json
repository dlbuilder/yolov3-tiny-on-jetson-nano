{
   "category": "Inference",
   "common": {
      "filterName": "TensorRTInferenceFilter",
      "os": "Windows10, Ubuntu18.04, Jetson4.4",
      "description": "Filter to inference model with TensorRT",
      "dependency": {
         "Windows10": [
            {
               "dependencyName": "tensorrt7.1.3.4",
               "inc": [
                  "include",
                  "common"
               ],
               "lib": {
                  "debug": [
                     "nvinfer.lib"
                  ],
                  "release": [
                     "nvinfer.lib"
                  ]
               }
            },
            {
               "dependencyName": "cudnn8.0.3.33",
               "inc": [
                  ""
               ],
               "lib": {
                  "debug": [],
                  "release": []
               }
            }
         ],
         "Ubuntu18.04": {
            "inc": [],
            "lib": [],
            "export": [],
            "install": []
         },
         "Jetson4.4": {
            "inc": [],
            "lib": [
               "/usr/lib/aarch64-linux-gnu/libnvinfer.so"
            ],
            "export": [],
            "install": []
         }
      },
      "runtime": []
   },
   "internalData": {
      "className": "TensorRTInferenceInternalData",
      "gpuID": "0",
      "model": "",
      "batchSize": "1",
      "plugins": []
   },
   "inputData": [
      {
         "className": "TensorRTInferenceInputData",
         "imageWidth": "",
         "imageHeight": "",
         "resizedImageWidth": "",
         "resizedImageHeight": "",
         "bgrData": ""
      }
   ],
   "outputData": {
      "className": "TensorRTInferenceOutputData",
      "imageWidth": "1920",
      "imageHeight": "1080",
      "resizedImageWidth": "",
      "resizedImageHeight": "",
      "tensorRTModelOutputCount": "",
      "tensorRTModelOutputs": "",
      "tensorRTModelOutputsSizes": ""
   }
}